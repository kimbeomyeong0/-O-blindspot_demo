import asyncio
from crawler.crawler_chosun import ChosunCrawler, CrawlerConfig as ChosunConfig
from crawler.crawler_joongang import JoongangCrawler, CrawlerConfig as JoongangConfig
from crawler.crawl_jtbc import JTBCNewsCrawler, CrawlerConfig
# ì•ìœ¼ë¡œ ì¶”ê°€ë  í¬ë¡¤ëŸ¬ë“¤ë„ ì—¬ê¸°ì— import

async def run_all_crawlers():
    chosun_config = ChosunConfig()
    joongang_config = JoongangConfig()
    jtbc_config = CrawlerConfig()  # JTBCìš© ì„¤ì •
    
    crawlers = [
        ChosunCrawler(chosun_config),
        JoongangCrawler(joongang_config),
        JTBCNewsCrawler(jtbc_config),
        # ì•ìœ¼ë¡œ 13ê°œ í¬ë¡¤ëŸ¬ë„ ì—¬ê¸°ì— ì¶”ê°€
    ]
    
    print("ğŸš€ ëª¨ë“  í¬ë¡¤ëŸ¬ ë™ì‹œ ì‹¤í–‰ ì‹œì‘")
    print("=" * 60)
    
    results = await asyncio.gather(*(c.crawl_all_categories() for c in crawlers))
    
    # ê²°ê³¼ í†µí•© ë° í†µê³„
    total_articles = sum(len(result) for result in results if result)
    print(f"\nğŸ‰ ëª¨ë“  í¬ë¡¤ëŸ¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ {total_articles}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
    print("=" * 60)
    
    return results

if __name__ == "__main__":
    asyncio.run(run_all_crawlers()) 