# 크롤러 개발 가이드라인

## 🕷️ 크롤러 구조
- [base.py](mdc:apps/backend/crawler/base.py): 모든 크롤러의 기본 클래스
- 언론사별 크롤러: [chosun.py](mdc:apps/backend/crawler/crawlers/chosun.py), [joongang.py](mdc:apps/backend/crawler/crawlers/joongang.py) 등

## 📋 개발 규칙

### 1. 통합 구조 유지
- 언론사별 별도 디렉토리 생성 금지
- 모든 크롤러는 `crawlers/` 디렉토리에 통합
- 기존 크롤러를 템플릿으로 참조

### 2. 일관된 피드백
- URL 리스트 출력 금지 (너무 많은 URL)
- 간결하고 명확한 진행 상황 표시
- 모든 크롤러의 피드백 스타일 통일

### 3. 데이터 저장
- 원시 데이터: `data/raw/` 디렉토리에 JSONL 형식
- 파일명: `{언론사명}_articles_{날짜}_{시간}.jsonl`
- 데이터베이스 저장 코드는 깔끔하고 간단하게
- 불필요한 HTTP 요청 로그 제거

### 4. HTML 구조 처리
- 전체 HTML 구조 제공 (CSS 선택자만 사용하지 않음)
- 명확한 데이터 추출 로직 구현

## 🚀 실행 방법
```bash
# 전체 크롤러 실행
python3 apps/backend/crawler/run_all_crawlers.py

# 개별 크롤러 실행
python3 apps/backend/crawler/crawlers/{언론사명}.py
```

## 📊 데이터 플로우
1. 크롤러가 언론사 기사 수집
2. 원시 데이터를 JSONL 형식으로 저장
3. 데이터베이스에 정제된 데이터 저장
4. 편향 분석 및 이슈 클러스터링
